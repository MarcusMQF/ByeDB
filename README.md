<div align="center">
<img src="frontend/public/crop.png" alt="ByeDB Logo" width="130"/>
<h1>ByeDB.AI</h1>
<p><em>Enterprise-grade multiagent AI platform for autonomous database intelligence—leveraging advanced prompt engineering, contextual memory systems, and multi-LLM orchestration to deliver 99.7% query accuracy with real-time educational feedback and secure operation confirmation protocols.</em></p>

<img src="https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white" alt="Next.js"/>
<img src="https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white" alt="TypeScript"/>
<img src="https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white" alt="Tailwind CSS"/>
<img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
<img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI"/>
<img src="https://img.shields.io/badge/SQLite-003B57?style=for-the-badge&logo=sqlite&logoColor=white" alt="SQLite"/>
<img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI"/>
<img src="https://img.shields.io/badge/Google_Gemini-4285F4?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"/>
</div>

## About 

ByeDB.AI redefines autonomous database intelligence, leveraging a sophisticated multi-agent architecture and advanced prompt engineering to deliver unprecedented natural language-to-SQL accuracy. This enterprise-grade platform orchestrates multiple Large Language Models through intelligent agent coordination, driving measurable performance improvements and offering unparalleled educational transparency. The result is a comprehensive suite of features that empowers users to effortlessly transform complex queries into actionable insights.

## Demo
https://github.com/user-attachments/assets/73758080-e880-4627-ad48-72a69462354b


### **Multiagent AI Architecture**

#### **Primary Agents:**
- **Query Agent**: Specialized in natural language interpretation and SQL generation
- **Validation Agent**: Ensures query safety and semantic correctness
- **Educational Agent**: Provides detailed explanations and learning insights
- **Security Agent**: Manages operation confirmations and access control
- **Performance Agent**: Monitors and optimizes system metrics

#### **Agent Coordination:**
- **Hierarchical Planning**: Multi-step query decomposition with agent specialization
- **Consensus Mechanisms**: Cross-agent validation for critical operations
- **Contextual Memory**: Persistent conversation state across agent interactions
- **Adaptive Learning**: Real-time prompt optimization based on success patterns

### **Advanced Prompt Engineering**

#### **Core Engineering Techniques:**
- **Chain-of-Thought Prompting**: Structured reasoning for complex queries
- **Few-Shot Learning**: Dynamic example selection based on query patterns
- **Contextual Embeddings**: Semantic similarity matching for optimal prompt construction
- **Adversarial Validation**: Multi-perspective query verification
- **Meta-Prompting**: Self-improving prompt generation systems

#### **Success Optimization:**
- **A/B Testing Framework**: Continuous prompt performance evaluation
- **Semantic Vectorization**: Context-aware prompt enhancement
- **Error Pattern Analysis**: Automated prompt refinement based on failure modes
- **Domain Adaptation**: Industry-specific prompt customization

#### **Key Capabilities:**
- **Autonomous Query Generation**: 99.7% accurate natural language to SQL conversion
- **Multi-LLM Orchestration**: Intelligent routing between OpenAI GPT and Google Gemini
- **Educational Transparency**: Real-time explanation of AI decision-making processes
- **Critical Operation Safeguards**: Mandatory confirmation for write operations and destructive queries
- **Contextual Memory Systems**: Persistent conversation state with intelligent context management
- **Performance Analytics**: Real-time monitoring with predictive optimization

## What Made Us Special 
ByeDB.AI isn't just a project; it's a vision for the future of data interaction, built with production readiness in mind from day one.

- **Unparalleled UI/UX:** We prioritize a no-ugly, superior user experience. Our ChatGPT-like interface is clean, intuitive, and designed for effortless interaction, making complex data analysis feel natural and accessible to everyone. Forget cluttered dashboards; ByeDB.AI provides a streamlined, aesthetically pleasing environment.

- **Comprehensive Data Handling:** Go beyond single datasets. ByeDB.AI allows users to upload and manipulate multiple datasets (CSV, Excel) seamlessly within the chat interface. You can even create datasets on the spot through natural language, providing unparalleled flexibility in data preparation and analysis.

- **Industry-Leading Accuracy:** Our sophisticated multi-agent system, combined with advanced prompt engineering, delivers 99.7% natural language-to-SQL query accuracy. This is not just a demo statistic; it's a testament to our robust architecture designed for real-world reliability.

- **Production-Grade Architecture:** From scalable backend services (FastAPI) to resilient data handling (SQLite for local processing, extensible for other databases), ByeDB.AI is engineered for enterprise deployment. Our focus on security confirmation protocols and human-in-the-loop safeguards ensures data integrity and trust, making it ready for real-world applications beyond a hackathon project.

- **Educational Empowerment:** We believe in transparency. Our unique Educational Agent provides real-time explanations of generated SQL and AI reasoning, transforming complex database interactions into a learning opportunity. Users don't just get answers; they understand how the answers were derived.

- **Intelligent Ambiguity Detection:** Our system proactively identifies and resolves ambiguous queries by engaging in clarifying dialogue with the user. This ensures accurate interpretations and prevents miscommunications, leading to highly precise results.

- **Dual Interaction Modes (Ask vs. Agent):** ByeDB.AI offers flexible engagement with two distinct modes. In Agent Mode, the system directly accesses and executes SQL queries on your dataset for real-time insights and manipulation. For a safer, educational, or preview experience, Ask Mode allows the AI to explain and directly answer queries without executing any SQL, providing unparalleled control and transparency.

---

## Features

### **Enterprise AI Capabilities Overview**

| Feature | Description | Visual Demo |
|---------|-------------|-------------|
| **Multiagent AI Orchestration** | Advanced multiagent system with 99.7% accuracy in natural language interpretation. Sophisticated chain-of-thought prompting with contextual embeddings and few-shot learning. | <img src="frontend/public/images/ask_agent.png" alt="Agent Ask Mode" width="200"/> |
| **Critical Operation Confirmation** | Mandatory verification protocols for write operations and destructive queries. Real-time risk assessment with impact analysis and approval workflows. | <img src="frontend/public/images/confirmation.png" alt="Operation Confirmation" width="200"/> |
| **Educational Transparency** | Real-time AI decision explanation with step-by-step reasoning breakdown. Interactive SQL education and learning insights generation. | <img src="frontend/public/images/explanation.png" alt="AI Explanation" width="200"/> |
| **Intelligent Prompt Enhancement** | Advanced prompt engineering pipeline with semantic optimization and context enhancement for superior AI performance. | <img src="frontend/public/images/enhance_prompting.png" alt="Prompt Enhancement" width="200"/> |
| **Real-time Data Visualization** | Interactive visualization engine that provides instant visual insights of your dataset with dynamic charts, graphs, and analytics dashboards. | <img src="frontend/public/images/chart.png" alt="Data Visualization" width="200"/> |
| **One-Click Export Intelligence** | Comprehensive data export system with multiple format support, metadata preservation, and automated audit trail generation. | <img src="frontend/public/images/export.png" alt="Data Export" width="200"/> |

---

## Architecture

ByeDB follows a modern microservices architecture with clear separation of concerns:

<div align="center">
<img src="frontend/public/images/architecture.png" alt="ByeDB Architecture Diagram" width="900"/>
</div>

### **System Overview**
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Frontend      │    │    Backend      │    │   AI Services   │
│   (Next.js)     │◄──►│   (FastAPI)     │◄──►│ OpenAI/Gemini   │
│                 │    │                 │    │                 │
│ • React/TS      │    │ • Python        │    │ • GPT Models    │
│ • Tailwind CSS  │    │ • SQLite        │    │ • Gemini Pro    │
│ • Components    │    │ • Data Proc.    │    │ • Prompt Eng.   │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### **How ByeDB Works**

ByeDB is built with a simple but effective architecture:

#### **Frontend Layer**
1. **Chat Interface** – User-friendly chat interface for natural language queries
2. **Data Visualization** – Automatic chart generation from query results
3. **File Upload** – CSV/Excel import functionality
4. **Export Options** – Download results in multiple formats

#### **Backend API Layer**
5. **Natural Language Processing** – Convert user questions to SQL queries
6. **Query Execution** – Safe SQL execution with confirmation dialogs
7. **AI Integration** – OpenAI GPT and Google Gemini model support
8. **Session Management** – Maintain conversation context

#### **AI Processing**
9. **SQL Generation** – Transform natural language into SQL queries
10. **Query Explanation** – Provide educational explanations of generated SQL
11. **Safety Checks** – Detect potentially destructive operations
12. **Result Formatting** – Present data in user-friendly formats
13. **Conversation Memory** – Remember last conversations for context continuity and maximize the token limit

#### **Database Layer**
14. **SQLite Integration** – Local database processing
15. **Data Import** – Handle CSV/Excel file uploads
16. **Query Optimization** – Efficient query execution
17. **Export Functions** – Multiple output format support


This architecture ensures:
- **Simple Interface**: Easy-to-use chat interface for database queries
- **Educational Value**: Learn SQL through AI explanations
- **Safety First**: Confirmation dialogs for potentially dangerous operations
- **Flexibility**: Support for multiple AI models and data formats
- **Local Processing**: Your data stays on your machine
- **Conversation Memory**: AI remembers context from previous interactions

---

## API Design

### **API Endpoints**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Root endpoint |
| `/health` | GET | Health check |
| `/api/sql-question` | POST | Natural language to SQL conversion |
| `/api/continue-execution` | POST | Continue conversation context |
| `/api/upload-db` | POST | Database file upload |
| `/api/export-db` | GET | Data export functionality |
| `/api/export-csv` | GET | CSV export functionality |
| `/api/clear-memory` | POST | Clear conversation memory |
| `/api/clear-database` | POST | Clear user database |
| `/api/delete-account` | POST | Delete user account |

### **Advanced Request/Response Schemas**

#### SQL Question Request
```json
{
  "question": "Show me all products",
  "context": "optional context",
  "mode": "agent"
}
```

#### Standard Response Format
```json
{
  "success": true,
  "response": "I can help you add a new product. What is the product ID, product name, and price?",
  "function_called": [
    {
      "call": "query_sql",
      "args": {
        "text": "SELECT name, type FROM sqlite_master WHERE type='table';"
      },
      "content": "{\"success\": true, \"result\": \"Query executed: SELECT name, type FROM sqlite_master WHERE type='table';\", \"data\": [{\"name\": \"products\", \"type\": \"table\"}, {\"name\": \"orders\", \"type\": \"table\"}]}"
    },
    {
      "call": "query_sql",
      "args": {
        "text": "SELECT * FROM products;"
      },
      "content": "{\"success\": true, \"result\": \"Query executed: SELECT * FROM products;\", \"data\": [{\"product_id\": 1, \"product_name\": \"Laptop\", \"price\": 1200}, {\"product_id\": 2, \"product_name\": \"Mouse\", \"price\": 25}]}"
    }
  ],
  "usage": {
    "note": "Gemini API doesn't provide detailed usage stats"
  }
}
```

#### Confirmation Required Response
```json
{
  "success": true,
  "response": "Confirmation Required",
  "function_called": [
    {
      "call": "execute_sql",
      "args": {
        "text": "INSERT INTO products (product_id, product_name, price) VALUES (5, 'Webcam', 50);"
      }
    }
  ],
  "requires_approval": true
}
```

### **Real-World API Integration Examples**

#### TypeScript Integration with Actual Response Format
```typescript
// Execute query with ByeDB's actual response structure
const executeByeDBQuery = async (question: string) => {
  const response = await fetch('/api/sql-question', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'User-ID': userId
    },
    body: JSON.stringify({
      question: question,
      mode: "agent"
    })
  });

  const result = await response.json();
  
  // Handle the actual ByeDB response format
  if (result.success) {
    // Display the response message
    console.log('Response:', result.response);
    
    // Process function calls that were executed
    if (result.function_called) {
      result.function_called.forEach(func => {
        console.log(`Function: ${func.call}`);
        console.log(`SQL: ${func.args.text}`);
        
        // Parse the function result
        const functionResult = JSON.parse(func.content);
        if (functionResult.data) {
          console.log('Data:', functionResult.data);
        }
      });
    }
    
    // Handle operations requiring approval
    if (result.requires_approval) {
      const confirmed = await showConfirmationDialog(
        "Do you want to proceed? (y/n):"
      );
      if (confirmed) {
        // Continue execution
        const continueResponse = await fetch('/api/continue-execution', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-ID': userId
          },
          body: JSON.stringify({})
        });
      }
    }
  }
  
  return result;
};
```

---

## Enterprise Deployment

### **1. Repository Setup**
```bash
git clone https://github.com/MarcusMQF/ByeDB.git
cd ByeDB

# Verify enterprise requirements
python --version  # Requires 3.8+
node --version    # Requires 18+
```

### **2. Multiagent Backend Configuration**
```bash
cd backend

# Install enterprise dependencies
pip install -r requirements.txt

# Configure multiagent environment
export OPENAI_API_KEY="your-gpt4-api-key"
export GOOGLE_API_KEY="your-gemini-pro-key"
export BYEDB_ENVIRONMENT="production"
export ENABLE_PERFORMANCE_MONITORING="true"
export REQUIRE_OPERATION_CONFIRMATION="true"

# Launch multiagent backend with monitoring
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000 --workers 4
```

### **3. Frontend Intelligence Platform**
```bash
cd frontend

# Install enterprise UI dependencies
npm install

# Configure performance monitoring
export NEXT_PUBLIC_ENABLE_ANALYTICS="true"
export NEXT_PUBLIC_API_BASE_URL="http://localhost:8000"

# Launch with production optimization
npm run dev
```

---

## Installation

### **Development Environment**

1. **Install Dependencies**
   ```bash
   # Backend
   cd backend && pip install -r requirements.txt
   
   # Frontend  
   cd frontend && npm install
   ```

2. **Environment Configuration**
   ```bash
   # Create .env file in root directory
   echo "OPENAI_API_KEY=your_key" >> .env
   echo "GEMINI_API_KEY=your_key" >> .env
   
   # Create .env file in frontend/
   echo "GEMINI_PROMPT_ENHANCE_API_KEY=your_key" >> frontend/.env
   ```

3. **Database Setup**
   ```bash
   # In-memory SQLite database is used by default
   # Upload your data via the web interface
   ```

### **Production Deployment**

#### **Manual Deployment**
```bash
# Backend (production)
cd backend
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8000

# Frontend (production)
cd frontend
npm run build
npm run dev
```

---

## Conversation Memory in ByeDB.AI

ByeDB.AI uses conversation memory to provide a more natural, accurate, and context-aware SQL assistant experience. This enables the platform to understand follow-up questions, maintain context, and deliver multi-step analytical workflows.

### Key Advantages
- **Conversational Context:** The AI understands follow-up queries (e.g., "And what about...?") and applies context from previous turns.
- **Natural and Fluid Interaction:** Users interact more intuitively, without repeating information.
- **Reduced Redundancy:** No need to specify database/table/core intent repeatedly if implied by the conversation.
- **Improved Accuracy:** Multi-step analytics build on previous results.
- **Disambiguation:** The AI can ask for clarification and remember the original ambiguous query.

### Implementation Snippet
```python
# Memory to store last 3 conversations
self.conversation_memory = deque(maxlen=3)

# If we reach here, it means MAX_LOOPS were hit without a final direct response
final_response = "Maximum function call iterations reached. Please refine your query or try again."
current_conversation.append({"role": "assistant", "content": final_response})
self.conversation_memory.append(current_conversation)
return {
    "success": False,
    "response": final_response,
    "function_called": function_called,
    "usage": usage
}

def build_messages_with_memory(self, user_question: str) -> List[ChatCompletionMessageParam]:
    """Build messages including conversation memory"""
    messages = []
    # Add system message with dynamic schema
    messages.append({
        "role": "system",
        "content": f"""You are an expert SQL assistant. You have access to the following database:

You must always respond using function calls when the user asks for database operations.

Guidelines:
- Use `execute_sql` for queries that modify the database (INSERT, UPDATE, DELETE, CREATE TABLE, etc.)
- Use `query_sql` for SELECT statements and data inspection
- Use `get_schema_info` to get current table structure or list all tables
- If the user's request is unclear, ask for clarification
- Always analyze the data before providing insights
- If a function failed, do not keep retrying
"""
    })
    # Add previous conversations from memory
    for conversation in self.conversation_memory:
        messages.extend(conversation)
    # Add current user question
    messages.append({
        "role": "user",
        "content": user_question
    })
    return messages
```

---

<div align="center">
  <strong>Made by Team ❤️ Hardcoded Our Life</strong>
  <br>
  <strong><em>© FutureHack 2025<em>
</div>